{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz0fBt7FMKu4ofMu8zzSLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junoflows/DeepLearning_From_Scratch1/blob/main/chapter_4_%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4 신경망 학습"
      ],
      "metadata": {
        "id": "JIQiVfNeDJgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것\n",
        "+ 손실 함수와 경사법에 대해 알아보자."
      ],
      "metadata": {
        "id": "xmjkTZlzDQsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 데이터에서 학습한다!"
      ],
      "metadata": {
        "id": "HymXaAL2DqB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 퍼셉트론에서는 진리표를 보며 사람이 수작업으로 매개변수 값을 설정했다.\n",
        "+ 층을 깊게 한 딥러닝의 경우 매개변수를 수작업으로 하는 것은 불가능하다.\n",
        "+ 신경망에 데이터를 보고 가중치 매개변수의 값을 자동으로 결장한다."
      ],
      "metadata": {
        "id": "22de-qDvDtM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 데이터 주도 학습"
      ],
      "metadata": {
        "id": "uaS51FHhEcfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 기계학습이란 데이터에서 답을 찾고 패턴을 발견하고 이야기를 만드는 것이다.\n",
        "+ 즉 기계학습의 중심에는 데이터가 존재한다.\n",
        "+ 기계학습은 사람의 개입을 최소화하고 수집한 데이터로 패턴을 찾는 시도를 한다."
      ],
      "metadata": {
        "id": "61J8Y6OTEe0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1LMcf7NiBBSMw_PAvATYYSxmtil7zTQQj' width = 400/><br>"
      ],
      "metadata": {
        "id": "PhiGfrZNHopd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 손글씨 이미지를 보고 5인지 아닌지 알아보는 프로그램을 구현하는 것이 목표이다.\n",
        "+ 사람마다 다르게 쓰이기 때문에 5를 특징짓는 규칙을 찾기 쉽지 않다.\n",
        "+ 따라서 5를 인식하는 알고리즘을 처음부터 설계하는 대신,  \n",
        "이미지에서 특징을 추출하고, 그 특징의 패턴을 기계학습 기술로 학습한다.\n",
        "+ 이미지 데이터를 벡터로 변환하고 지도 학습 방식의 대표 분류 기법인 SVM, KNN 등으로 학습할 수 있다.\n",
        "+ 모아진 데이터로부터 규칙을 찾아내는 역할을 '기계'가 담당한다.\n",
        "+ 다만, 이미지를 벡터로 변환할 때 사용하는 특징은 여전히 사람이 설계한다."
      ],
      "metadata": {
        "id": "V7InBL4MHt02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망과 딥러닝은 기존 기계학습에서의 방법보다 사람의 개입을 더욱 배제할 수 있게 해준다."
      ],
      "metadata": {
        "id": "2FDu7Lm7Q1Rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=11YD_PEQ-HymZ-VZifEVsQ8SgTuWyUrts' height = 300/><br>"
      ],
      "metadata": {
        "id": "g99ZwGOFPENH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 기계학습 방식은 위 그림의 중간과 같고,  \n",
        "신경망(딥러닝) 방식은 위 그림의 맨 아래처럼 사람이 개입하지 않는 블록 하나로 그려진다.\n",
        "+ 위 그림에서 알 수 있듯 기계학습 방식에는 특징을 사람이 설계했지만,  \n",
        "신경망은 이미지에 포함된 중요한 특징도 기계가 스스로 학습한다."
      ],
      "metadata": {
        "id": "WR8as0_FPKCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망의 이점은 모든 문제를 같은 맥락에서 풀 수 있다는 점에 있다.\n",
        "+ 숫자 뿐만 아니라 동물, 사람을 인식하는 문제 등 세부사항과 관계없이  \n",
        "주어진 데이터를 학습하고 패턴을 발견하려 시도한다.\n",
        "+ 신경망은 모든 문제를 주어진 데이터 그대로 입력 데이터로 활용해 end-to-end으로 학습할 수 있다."
      ],
      "metadata": {
        "id": "IUO4ncT0RNt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2 훈련 데이터와 시험 데이터"
      ],
      "metadata": {
        "id": "uOV4d_ULRoI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 기계학습 문제는 훈련 데이터와 시험 데이터로 나눠 학습과 실험을 수행하는 것이 일반적이다.\n",
        "+ 시험 데이터를 사용하여 훈련한 모델의 실력을 평가한다.\n",
        "+ 데이터셋 하나로만 매개변수의 학습과 평가를 수행하면 과적합의 문제가 발생할 수 있다.\n",
        "+ 과적합의 문제를 피하는 것도 기계학습의 중요한 과제이다."
      ],
      "metadata": {
        "id": "7HQuznW1jHzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 손실 함수"
      ],
      "metadata": {
        "id": "46txS5eVkb67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망 학습에서는 현재의 상태를 '하나의 지표'로 표현하고.  \n",
        "그 지표를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색한다.\n",
        "+ 신경망 학습에서 사용하는 지표는 __손실 함수__ 라고 한다.\n",
        "+ 손실 함수는 일반적으로 오차제곱합과 교차 엔트로피 오차를 사용한다."
      ],
      "metadata": {
        "id": "N5JENE5rRVUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__  \n",
        "손실 함수는 신경망 성능의 나쁨을 나타내는 지표로,  \n",
        "현재 신경망이 훈련 데이터를 얼마나 잘 처리하지 못하느냐를 나타낸다."
      ],
      "metadata": {
        "id": "7RkpkzsGRsox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 오차제곱합"
      ],
      "metadata": {
        "id": "kDbCMiMMR5P5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 가장 많이 쓰이는 손실 함수는 오차제곱합이다. 수식은 아래와 같다."
      ],
      "metadata": {
        "id": "BiK4axV5UE7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$  E = \\frac{1}{2}\\sum_{k} (y_k - t_k)^2 $"
      ],
      "metadata": {
        "id": "PQ0rmkaFUIlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ $y_k $는 싱경망의 출력(신경망이 추정한 값), $t_k$는 정답 레이블, $k$는 데이터의 차원 수를 나타낸다."
      ],
      "metadata": {
        "id": "XnMAIvHeWDiS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--82uqXmDEh1"
      },
      "outputs": [],
      "source": [
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 배열들의 원소는 첫 번째 인덱스부터 순서대로 숫자 0,1,2 ... 일 때의 값이다.\n",
        "+ 신경망의 출력 y 는 소프트맥스 함수의 출력이다.\n",
        "+ 이 예에서 이미지가 0일 확률은 0.1, 1일 확률은 0.05로 해석된다.\n",
        "+ 정답 레이블인 t는 정답인 원소는 1로, 아닌 것은 0으로 표기한다.\n",
        "+ 여기서 원소가 1인 값의 인덱스는 2이므로 정답이 2임을 알 수 있다.\n",
        "+ 이처럼 한 원소만 1로 하고 나머지는 0으로 나타내는 표기법을 __원-핫 인코딩__ 이라고 한다.\n"
      ],
      "metadata": {
        "id": "jm7TB1AfYaO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 앞서 언급한 오차제곱합을 파이썬으로 구현해보자."
      ],
      "metadata": {
        "id": "nuwJnmZyaRVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sum_squares_error(y, t):\n",
        "  return 0.5 * np.sum((y-t)**2)"
      ],
      "metadata": {
        "id": "wOX84sd9WR8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 함수를 실제로 사용해보자."
      ],
      "metadata": {
        "id": "dhtt8g3zbHkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정답은 '2'\n",
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "# 예1 : '2'일 확률이 가장 높다고 추정(0.6)\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "sum_squares_error(np.array(y), np.array(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqlbQ_EIaoKk",
        "outputId": "a48be05e-65ca-4beb-cece-8682042949b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09750000000000003"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예2 : '7'일 확률이 가장 높다고 추정(0.6)\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "sum_squares_error(np.array(y), np.array(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D1srLgqbRw_",
        "outputId": "bf212123-52a9-4302-a9f1-27332b446b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5975"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 첫 번째 예는 젇답이 2 이고 신경망의 출력도 2 에서 가장 높은 경우다.\n",
        "+ 두 번째 예는 정답은 2 지만 신경망의 출력은 7에서 가장 높다.\n",
        "+ 첫 번째 예의 손실 함수 출력이 작으며 정답 레이블과 오차도 작은 것을 알 수 있다.\n",
        "+ 즉 오차제곱합 기준으로 첫 번째 추정 결과가 정답에 더 가까울 것으로 판단할 수 있다."
      ],
      "metadata": {
        "id": "NEWYbZ9jdJZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2 교차 엔트로피 오차"
      ],
      "metadata": {
        "id": "m4NEoYeadhzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 또 다른 손실 함수로서 교차 엔트로피 오차도 자주 사용한다. 수식은 다음과 같다."
      ],
      "metadata": {
        "id": "bsNexoMJecdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$  E = -\\sum_{k} t_k log (y_k) $"
      ],
      "metadata": {
        "id": "rokywx4AegOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 여기에서 log 는 밑이 e인 자연로그이다.\n",
        "+ $y_k$는 신경망의 출력, $t_k$는 정답 레이블이다.\n",
        "+ $t_k$는 정답에 해당하는 인덱스의 원소만 1이고 나머지는 0이다. (원-핫 인코딩)\n",
        "+ 실질적으로 정답일 때의 추정의 자연로그를 계산하는 식이다."
      ],
      "metadata": {
        "id": "Lk2VrWZwev3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예를 들어 정답 레이블은 2가 정답이라 하고 신경망 출력이 0.6이라면 교차 엔트로프 오차는 -log0.6 = 0.51이 된다.  \n",
        "같은 조건에서 신경망 출력이 0.1 이라면 -log0.1 = 2.30 이다.  \n",
        "즉 교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정하게 된다."
      ],
      "metadata": {
        "id": "LDVrOD6Ffs43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1EwbqMzq5y-4CmVNYeZo86LB3Zd_ItUtH' height = 300 /><br>"
      ],
      "metadata": {
        "id": "60BPbYPgf_go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ x가 1일 때 y는 0이 되고 x가 0에 가까워질수록 y의 값은 점점 작아진다.\n",
        "+ 정답일 때의 출력이 커질수록 0에 다가가다가 1일 때 0이 된다. 반대로 정답일 때의 출력이 작아질수록 오차는 커진다.\n",
        "+ 교차 엔트로피 오차를 구현해보자."
      ],
      "metadata": {
        "id": "gkzVJzVogZ4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t * np.log(y + delta))"
      ],
      "metadata": {
        "id": "KIanYtBVbkrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ y, t는 넘파이 배열이다.\n",
        "+ np.log계산에서 아주 작은 delta를 더하는 이유는 np.log()에 0을 입력하면 -inf가 되기 때문에 이를 방지하기 위함이다.\n",
        "+ 위 함수를 써서 간단한 계산을 해보자."
      ],
      "metadata": {
        "id": "6XrkpNIuhel5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isGcMNBVg2eP",
        "outputId": "bad5a7f1-60f4-4560-a255-efc7aa8764cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510825457099338"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "metadata": {
        "id": "PdxCYCHWh9wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff29fb22-0793-4cb3-84f4-ec9cc51a1361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.302584092994546"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 첫 번째 예는 정답일 때 출력이 0.6인 경우고 이 때 교차 엔트로피 오차는 약 0.51dlek\n",
        "+ 두 번쩨 예는 정답일 때 출력이 0.1인 경우고, 이때의 교차 엔트로피 오차는 2.3이다.\n",
        "+ 오차 값이 더 작은 첫 번째 추정이 정답일 가능성이 높다고 판단한 것으로 오차제곱합 판단과 일치한다."
      ],
      "metadata": {
        "id": "Gm9I2wwpiCfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.3 미니배치 학습"
      ],
      "metadata": {
        "id": "vCQ0PbyriWuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 기계학습 문제는 훈련 데이터에 대한 손실 함수의 값을 구하고, 그 값을 최대한 줄여주는 매개변수를 찾아낸다.\n",
        "+ 이렇게 하려면 모든 훈련 데이터를 대상으로 손실 함수 값을 구해야 한다.\n",
        "+ 모든 훈련 데이터를 대상으로 한 교차 엔트로피 오차 수식은 다음과 같다."
      ],
      "metadata": {
        "id": "V0lmJzUyi_k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$  E = -\\frac{1}{N} \\sum_{n} \\sum_{k} t_{nk} log (y_{nk}) $"
      ],
      "metadata": {
        "id": "8Ug2XfemmqjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 데이터가 N개라면 $t_{nk}$는 n번째 데이터의 k번째 값을 의미한다. ($y_{nk}$ 는 신경망의 출력 $t_{nk}$는 정답 레이블)\n",
        "+ 손실 함수를 N개의 데이터로 확장하고, 마지막에 N으로 나누어 정규화한다.\n",
        "+ 이렇게 '평균 손실 함수'를 구해 사용하면 훈련 데이터 개수와 관계없이 언제든 통일된 지표를 얻을 수 있다."
      ],
      "metadata": {
        "id": "_qHTAAWWoD0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 그런데 MNIST 데이터셋은 훈련 데이터가 60,000개 이므로  \n",
        "모든 데이터를 대상으로 손실 함수의 합을 구하려면 시간이 오래 걸린다.\n",
        "+ 더 나아가 빅데이터에서는 수백만 ~ 수천만이 넘는 데이터를 대상으로 손실 함수를 계산하는 것은 현실적이지 않다.\n",
        "+ 이런 경우 데이터 일부를 추려 전체의 '근사치'로 이용할 수 있다.\n",
        "+ 이 일부를 미니 배치라고 한다. 예를 들어 60,000 훈련 데이터 중에서 100장만 무작위로 뽑아서 학습하는 것이다.\n",
        "+ 이런 학습 방법을 미니배치 학습이라고 한다."
      ],
      "metadata": {
        "id": "53SFvg-7pPhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 미니배치 학습을 구현하는 코드를 작성해보자."
      ],
      "metadata": {
        "id": "rToe_I1yqRln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax_h7ExFsFKS",
        "outputId": "c1543a64-2e2d-4915-938d-eaa1edf1cdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-master/')\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "  load_mnist(normalize = True, one_hot_label= True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqmrdzE3qKzW",
        "outputId": "70bcb6b8-ea98-48bd-85c9-64842629aa43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ load_mnist 함수로 MNIST 데이터셋 훈련 데이터와 시험 데이터를 읽는다.\n",
        "+ 호출할 때 one_hot_label= True 로 지정하여 원-핫 인코딩으로 한다.\n",
        "+ 데이터를 읽은 결과 훈련 데이터는 60,000개, 입력 데이터는 784열(원래는 28×28)인 데이터임을 알 수 있다.\n",
        "+ 정답 레이블은 10줄짜리 데이터이다.  \n",
        "따라서 x_train, t_train의 모습은 각각 (60000, 784), (60000,10)이 된다.\n",
        "+ 이 훈련 데이터에서 무작위로 10장만 빼내기 위해서는 np.random.choice() 함수를 쓰면 된다."
      ],
      "metadata": {
        "id": "LmGklCK7tfRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "metadata": {
        "id": "eAmZDhB6r8J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ np.random.choice() 는 지정한 범위의 수 중 무작위로 원하는 개수만 꺼낼 수 있다.\n",
        "+ 다음 예시를 살펴보자."
      ],
      "metadata": {
        "id": "QfD8L-zuusgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 60000 미만의 수 중에서 무작위로 10개를 골라낸다.\n",
        "np.random.choice(60000,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW5bTbb4umf7",
        "outputId": "5e807b3e-c2df-4e92-ed2c-9ae9142d7ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([58849, 59586, 16852, 47152, 44205, 36922,  6828, 13444, 35887,\n",
              "       58139])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 무작위로 선택한 이 인덱스를 사용해 미니배치를 뽑아내면 된다. 손실 함수도 미니배치로 계산한다."
      ],
      "metadata": {
        "id": "3iXROIqPu-kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__  \n",
        "미니배치의 손실 함수는 일부 표본 데이터로 전체를 비슷하게 계측한다.  \n",
        "전체 훈련 데이터의 대표로서 무작위로 선택한 미니배치를 사용하는 것이다."
      ],
      "metadata": {
        "id": "I9oR1zed67am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.4 (배치용) 교차 엔트로피 오차 구하기"
      ],
      "metadata": {
        "id": "4phZqHFE7J-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 배치 데이터를 지원하는 교차 엔트로피 오차를 구현해보자.  \n",
        "앞서 구현한 교차 엔트로피 오차를 조금만 바꿔주면 된다."
      ],
      "metadata": {
        "id": "qUN8yvqR7P1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(t * np.log(y + 1e-7)) / batch_size"
      ],
      "metadata": {
        "id": "InoMMuq-u2jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ y는 신경망의 출력, t는 정답 레이블이다.\n",
        "+ y가 1차원, 즉 데이터 하나당 교차 엔트로피 오차를 구하는 경우는 reshape 함수로 데이터 형상을 바꿔준다.\n",
        "+ 그리고 배치 크기로 나눠 정규화하고 이미지 1장당 평균의 교차 엔트로피 오차를 계산한다."
      ],
      "metadata": {
        "id": "tLdt7_e-707A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 정답 레이블이 원-핫 인코딩이 아니라 2나 7 등의 숫자 레이블로 주어졌을 때의 교차 엔트로피 오차 구현은 다음과 같다."
      ],
      "metadata": {
        "id": "kW5L1T0p8L3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(np.log(y[np.arange(batch_size),t] + 1e-7)) / batch_size"
      ],
      "metadata": {
        "id": "z_Q8C1DK7uks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 원-핫 인코딩일 때 t가 0인 원소는 교차 엔트로피 오차도 0이고 그 계산은 무시해도 된다는 것이 핵심이다.\n",
        "+ 즉 정답에 해당하는 신경망의 출력만으로 교차 엔트로피 오차를 계산할 수 있다.\n",
        "+ 원-핫 인코딩 시 t * np.log(y) 인 부븐을 레이블 표현일 때는 np.log(y[np.arange(batch_size),t])로 구현한다."
      ],
      "metadata": {
        "id": "FK5fTWvB8rZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ np.arange(batch_size)는 0부터 batch_size - 1 까지 배열을 생성한다.\n",
        "+ batch_size가 5이면 np.arange(batch_size)는 [0,1,2,3,4] 넘파이 배열을 생성한다.\n",
        "+ t에는 [2,7,0,9,4]와 같이 저장되어 있으므로  \n",
        "y[np.arange(batch_size),t]는 각 데이터의 정답 레이블에 해당하는 신경망의 출력을 추출한다.  \n",
        "(이 예에서는 [y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]]인 넘파이 배열을 생선한다.)"
      ],
      "metadata": {
        "id": "koCy39Vv9MZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.5 왜 손실 함수를 설정하는가?"
      ],
      "metadata": {
        "id": "cQn2q29g-Rrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 숫자 인식의 궁극적인 목적은 높은 '정확도'를 끌어내는 매개변수 값을 찾는 것이다.\n",
        "+ '정확도'라는 지표 대신 '손실 함수의 값' 을 택하는 이유는 무엇일까?\n",
        "+ 이 의문은 신경망 학습에서의 '미분'의 역할에 주목하면 해결된다.\n",
        "+ 신경망 학습에서 최적의 매개변수를 탐색할 때 손실 함수의 값을 가능한 작게하는 매개변수 값을 찾는다.\n",
        "+ 이때 매개변수의 미분을 계산하고, 그 값을 단서로 매개변수의 값을 갱신하는 과정을 반복한다.\n",
        "+ 정확도를 지표로 삼으면 안되는 이유는 미분 값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없기 떄문이다.\n",
        "+ 구체적인 예를 살펴보자."
      ],
      "metadata": {
        "id": "7djJ43uw-XMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "한 신경망이 100장의 훈련 데이터 중 32장을 올바로 인식한다고 하자."
      ],
      "metadata": {
        "id": "jZRYf5ZR_F0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 경우 정확도는 32%이다. 만약 정확도가 지표라면 가중치 매개변수 값을 조금 바꿔도 정확도는 32%로 유지된다.\n",
        "+ 즉 매개변수를 약간만 조정해서는 정확도가 개선되지 않고 일정하게 유지된다.\n",
        "+ 반면 손실 함수를 지표로 삼는다고 가정하자.\n",
        "+ 손실 함수의 값은 0.92543.. 같은 수치로 나타난다.\n",
        "+ 매개변수 값이 조금 변하면 그에 반응하여 손실 함수의 값도 0.93432.. 처럼 연속적으로 변화한다."
      ],
      "metadata": {
        "id": "9pdXh74P_8ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 정확도는 매개변수의 미세한 변화에는 거의 반응을 보이지 않고, 반응이 있더라도 값이 불연속적으로 갑자기 변화한다.\n",
        "+ 이는 '계단 함수'를 활성화 함수로 사용하지 않는 이유와 비슷하다."
      ],
      "metadata": {
        "id": "YVfLopyvAdVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1I3-Iz_kb-HrInZ45q2BaXpittGtBRk_w' width = 600 /><br>"
      ],
      "metadata": {
        "id": "O0xCIDrHBmIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 계단 함수의 미분은 0 을 제외하곤 0이다. 즉 계단 함수를 이용하면 손실 함수를 지표로 삼는 게 의미가 없게 된다.\n",
        "+ 시그모이드 함수의 미분은 어느 장소라도 0이 되지 않는다.\n",
        "+ 이는 신경망 학습에서 중요한 성질로, 기울기가 0이 되지 않는 덕분에 신경망이 올바르게 학습할 수 있다."
      ],
      "metadata": {
        "id": "DFhgQC6sCkAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 수치 미분"
      ],
      "metadata": {
        "id": "lPuvLi3UFzhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 경사법에서는 기울기 값을 기준으로 나아갈 방향을 정한다."
      ],
      "metadata": {
        "id": "8XNlHtswGae4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.1 미분"
      ],
      "metadata": {
        "id": "QLYhCxxOJQLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 미분에 대한 자세한 설명은 생략한다.\n",
        "+ 미분은 순간변화량을 표시한 것으로 수식은 다음과 같다."
      ],
      "metadata": {
        "id": "PTiku7_DJTLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\Large{} \\frac{df(x)}{dx} =\n",
        "\\lim_{h \\to \\infty} \\frac{f(x+h)- f(x)}{h}\n",
        "$"
      ],
      "metadata": {
        "id": "MHWuQ0HMKt3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 식을 파이썬으로 구현해보자."
      ],
      "metadata": {
        "id": "wEY9i-SSNTgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 나쁜 구현 예\n",
        "def numerical_diff(f, x):\n",
        "  h = 1e-50\n",
        "  return (f(x + h) - f(x)) / h"
      ],
      "metadata": {
        "id": "JgaL4Xv88mrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 함수의 이름은 수치 미분에서 따왔다.\n",
        "+ 위 구현은 문제가 없어 보이지만 2가지 개선할 점이 있다."
      ],
      "metadata": {
        "id": "5cq0_RKdP6p8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "반올림 오차 문제"
      ],
      "metadata": {
        "id": "8XZauy5DQ3nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ h에 작은 값을 대입하기 위해 1e-50을 사용했는데 이 방식은 반올림 오차 문제를 일으킨다."
      ],
      "metadata": {
        "id": "U_pghEN1Q2-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.float32(1e-50)"
      ],
      "metadata": {
        "id": "2UCucBy1QCnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7360a8-7efe-4015-ac1e-628bbb1741b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 너무 작은 값을 사용하면 컴퓨터로 계산하는데 문제가 된다. 따라서 h를 $ 10^{-4} $ 값을 사용한다."
      ],
      "metadata": {
        "id": "i_hthykSQjNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "f의 차분"
      ],
      "metadata": {
        "id": "m7htSa_qQ7Jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 앞선 구현에서 x+h와 x 사이의 함수 f의 차분을 계산하고 있지만 이 계산에는 오차가 존재한다.\n",
        "+ 미분은 x 위치의 접선의 기울기에 해당하지만 위 구현에서는 x+h 와 x 사이의 기울기에 해당한다.\n",
        "+ 이 차이는 h를 무한히 0으로 좁히는 것이 불가능해 생기는 한계이다."
      ],
      "metadata": {
        "id": "acEj3uYuRHCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=19FM6480tn6f39klt4gcYDa3oDKNh2h0F' height = 300 /><br>"
      ],
      "metadata": {
        "id": "eMtnf4wEZe6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이와 같이 수치 미분에는 오차가 포함되는데 이를 줄이기 위해 f의 차분을 계산하는 방법을 쓴다.\n",
        "+ 이 차분은 x를 중심으로 그 전후의 차분을 계산한다는 의미에서 __중심(중앙) 차분__ 이라 한다."
      ],
      "metadata": {
        "id": "9FsU7bMrZizs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 두 개선점을 적용해 수치 미분을 다시 구현해보자."
      ],
      "metadata": {
        "id": "1tVlEM6MZ9A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numerical_diff(f, x):\n",
        "  h = 1e-4\n",
        "  return (f(x + h) - f(x-h)) / (2*h)"
      ],
      "metadata": {
        "id": "-WtDVM02QivD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.2 수치 미분의 예"
      ],
      "metadata": {
        "id": "4q6feetVaQNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 수치 미분을 사용하여 간단한 함수를 미분해보자."
      ],
      "metadata": {
        "id": "93AFVmjRaTHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ y = 0.01x^{2} + 0.1x\n",
        "$"
      ],
      "metadata": {
        "id": "Vo1CIrwFaXxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function_1(x):\n",
        "  return 0.01 * x **2 + 0.1 * x"
      ],
      "metadata": {
        "id": "M4LiKiwuaSze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1) # 0~20까지 0.1 간격의 배열 x를 만든다(20은 미포함).\n",
        "y = function_1(x)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.plot(x,y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P2sit_xWakG6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "9dbb1d6a-0815-4017-a26f-f6d7c2e4976c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ x = 5 일 때와 x = 10 일 때 이 함수의 미분을 계산해보자."
      ],
      "metadata": {
        "id": "wYAEs3fma9Im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(numerical_diff(function_1 , 5))\n",
        "print(numerical_diff(function_1 , 10))"
      ],
      "metadata": {
        "id": "qTNA7R6va7MA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "917c7228-0b37-488c-bae5-d39385b70653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1999999999990898\n",
            "0.2999999999986347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 앞에서 구한 수치 미분 값을 기울기로 하는 직선을 그려보자.  \n",
        "함수의 접선에 해당하는 것을 알 수 있다."
      ],
      "metadata": {
        "id": "Vc_G2DqmbbaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1ak9CI5j7U-KsUaj5jEOOy77dM4UNft5E' /><br>"
      ],
      "metadata": {
        "id": "1aJyp11Sb3y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.3 편미분"
      ],
      "metadata": {
        "id": "boTwN7FdcAhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+  다음은 변수가 2개인 함수이다. 파이썬으로 구현해보자."
      ],
      "metadata": {
        "id": "MB-vFeC2cBGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ f(x_0,x_1) = x_0^{2} + x_1^{2}\n",
        "$"
      ],
      "metadata": {
        "id": "URxr7EW7cElZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function_2(x):\n",
        "  return x[0] ** 2 + x[1] ** 2"
      ],
      "metadata": {
        "id": "HUI0SUN8bNMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 그래프로 그려보면 다음과 같이 3차원으로 그려진다."
      ],
      "metadata": {
        "id": "bWWcC2W3ce8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1f0Jjzpn25o82HIduB_8w5NdvrJAqrheq' height = 300 /><br>"
      ],
      "metadata": {
        "id": "lLLI1wf2co3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 식을 미분해보자. 변수가 2개이므로 어느 변수에 대한 미분인지를 구별해야한다.\n",
        "+ 이처럼 변수가 여럿인 함수에 대한 미분을 __편미분__ 이라고 한다.\n",
        "+ 편미분을 수식으로는 $ \\frac{\\partial f}{\\partial x_0} 나  \\frac{\\partial f}{\\partial x_1}$ 처럼 쓴다.\n",
        "+ 간단한 편미분 예제를 풀어보자."
      ],
      "metadata": {
        "id": "8wnU7W-zc44P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제1 : x0 = 3, x1 = 4일 때, x0에 대한 편미분 df/dx0 을 구하라.\n",
        "def function_tmp1(x0):\n",
        "  return x0 * x0 + 4.0 ** 2.0\n",
        "\n",
        "numerical_diff(function_tmp1, 3.0)"
      ],
      "metadata": {
        "id": "qrr-zvDzcZ_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e56690-35a0-4b9e-f120-f4fc688f1f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.00000000000378"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제2 : x0 = 3, x1 = 4일 때, x0에 대한 편미분 df/dx1 을 구하라.\n",
        "def function_tmp2(x1):\n",
        "  return 3.0 ** 2.0 + x1 * x1\n",
        "\n",
        "numerical_diff(function_tmp2, 4.0)"
      ],
      "metadata": {
        "id": "gSV2NTROd6gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccee90c-33ff-4ca0-de7f-19c3176ba716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.999999999999119"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 문제들은 변수가 하나인 함수를 정의하고, 그 함수를 미분하는 형태로 구현하여 풀었다.\n",
        "+ 이처럼 편미분은 여러 변수 중 목표 변수에 초점을 맞추고 다른 변수 값은 고정한다."
      ],
      "metadata": {
        "id": "Igs_CzrwlOPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 기울기"
      ],
      "metadata": {
        "id": "CaH32nR4lfVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 예에서는 $x_0$와 $x_1 $의 편미분을 변수별로 따로 계산했다.\n",
        "+  $x_0$와 $x_1$의 편미분을 동시에 계산하려면 어떻게 해야할까?\n",
        "+ $( \\frac{\\partial f}{\\partial x_0} ,  \\frac{\\partial f}{\\partial x_1}$)처럼 모든 변수의 편미분을 묶어서 변수로 정리한 것을 __기울기__라고 한다.\n",
        "+ 기울기는 아래와 같이 구현할 수 있다."
      ],
      "metadata": {
        "id": "rPystJrSlgjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numerical_gradient(f, x):\n",
        "  h = 1e-4 # 0.0001\n",
        "  grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
        "\n",
        "  for idx in range(x.size):\n",
        "    # f(x+h) 계산\n",
        "    tmp_val = x[idx]\n",
        "    x[idx] = tmp_val + h\n",
        "    fxh1 = f(x)\n",
        "\n",
        "    # f(x-h) 계산\n",
        "    x[idx] = tmp_val - h\n",
        "    fxh2 = f(x)\n",
        "\n",
        "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "    x[idx] = tmp_val # 값 복원\n",
        "\n",
        "  return grad"
      ],
      "metadata": {
        "id": "wmm3wl_aMNSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ numerical_gradient(f, x)의 인수인 f는 함수이고 x는 넘파이 배열이므로  \n",
        "x의 각 원소에 대해 수치 미분을 구한다.\n",
        "+ 세 점 (3,4), (0,2), (3,0)에서의 기울기를 구해보자."
      ],
      "metadata": {
        "id": "nCTyUq71T366"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
        "print(numerical_gradient(function_2, np.array([0.0, 2.0])))\n",
        "print(numerical_gradient(function_2, np.array([3.0, 0.0])))"
      ],
      "metadata": {
        "id": "vygc5vqPT3MH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff633525-716b-4cdc-c65c-10951e4daaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6. 8.]\n",
            "[0. 4.]\n",
            "[6. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 여기서 기울기가 의미하는 것이 무엇일까?  \n",
        "기울기의 결과에 마이너스를 붙인 벡터를 그려보자."
      ],
      "metadata": {
        "id": "OcF2eSmCZCHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1c5O08auMhOg7829qoEnC3RleKF6N_fPy' height = 300 /><br>"
      ],
      "metadata": {
        "id": "ZbnKKNDlnCZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 화살표들은 한 점을 향하고 있고 최솟값에서 멀어질수록 화살표의 크기가 커짐을 알 수 있다.\n",
        "+ __기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향__이다."
      ],
      "metadata": {
        "id": "XnzCVlzZZu3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.1 경사법(경사 하강법)"
      ],
      "metadata": {
        "id": "6_9CmQsdalyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망은 학습 시에 손실 함수가 최소가 되는 최적의 매개변수를 찾아야한다.\n",
        "+ 일반적으로 손실 함수는 매우 복잡한데,  기울기를 이용해서 함수의 최솟값을 찾는 방법이 경사법이다.\n",
        "+ 각 지점에서 함수의 값을 낮추는 방안을 제시하는 지표가 기울기이다.\n",
        "+ 하지만 복잡한 함수에서는 기울기가 가리키는 방향에 최솟값이 없는 경우가 대부분이다.\n",
        "+ 기울어진 방향이 꼭 최솟값을 가리키는 것은 아니나, 그 방향으로 가야 함수의 값을 줄일 수 있다.\n"
      ],
      "metadata": {
        "id": "72xW9-kNa3Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 경사법은 현 위치에서 기울어진 방향으로 일정 거리만큼 이동하고  \n",
        "마찬가지로 기울기를 구하고 일정 거리만큼 이동한다.\n",
        "+ 이렇게 함수 값을 점차 줄이는 것이 __경사법__이다.\n",
        "+ 경사법을 수식으로 표현해보자."
      ],
      "metadata": {
        "id": "DLd8wn-Scw6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ \\Large x_0 = x_0 - η\\frac{∂f}{∂x_0} \\\\\n",
        "\\Large x_1 = x_1 - η\\frac{∂f}{∂x_1}\n",
        "$\n"
      ],
      "metadata": {
        "id": "sfBjPVj3eMYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ η(에타)는 학습률이라 하고 한 번의 학습으로 얼마만큼 학습해야 할 지,  \n",
        "즉 매개변수 값을 얼마나 갱신하느냐를 정하는 값이다.\n",
        "+ 학습률 값은 0.01이나 0.001 등 특정 값으로 정해두어야 한다.\n",
        "+ 너무 크거나 작으면 올바른 학습이 되지 않기 때문에  \n",
        "학습률 값을 변경하면서 올바르게 학습하고 있는지를 확인하면서 진행한다.\n",
        "+ 경사 하강법을 파이썬으로 구현해보자."
      ],
      "metadata": {
        "id": "LIi7-kNif5Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(f, init_x, lr = 0.01, step_num = 100):\n",
        "  x = init_x\n",
        "\n",
        "  for i in range(step_num):\n",
        "    grad = numerical_gradient(f, x)\n",
        "    x -= lr * grad\n",
        "  return x"
      ],
      "metadata": {
        "id": "oYqz5P94ZccR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f** : 최적화하려는 함수  \n",
        "**init_x** : 초깃값  \n",
        "**lr** : learnig rate을 의미하는 학습률  \n",
        "**step_num** : 경사법에 따른 반복 횟수"
      ],
      "metadata": {
        "id": "KB6WTLlGi5VB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 함수를 사용하면 함수의 극솟값을 구할 수 있고, 잘하면 최솟값을 구할 수 있다.\n",
        "+ 경사법을 활용한 예제를 풀어보자."
      ],
      "metadata": {
        "id": "wmvTwQRRjPsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 : 경사법으로 f(x0, x1) = x0^2 + x1^2 의 최솟값을 구하라.\n",
        "def function_2(x):\n",
        "  return x[0] ** 2 + x[1] ** 2\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)"
      ],
      "metadata": {
        "id": "bkt7ZqfwhWSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32645b81-0c57-4289-a80e-0cb05441f9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 초깃값 (-3.0, 4.0)에서 경사법을 사용하여 최솟값 (-6.1e-10, 8.1e-10)을 얻었다.\n",
        "+ 실제 최솟값은 (0,0)으로 경사법으로 거의 정확한 결과를 얻은 것이다.\n",
        "+ 위 과정을 그림으로 나타내보자.\n",
        "+ 값이 원점에 점점 가까워지는 것을 알 수 있다."
      ],
      "metadata": {
        "id": "5vjAxJuWi01t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1SSzyxCuH9_kvhim0O4ztlwsDdPcx-7tn' height = 300/><br>"
      ],
      "metadata": {
        "id": "-HsMzk4cnG08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 학습률이 너무 큰 경우와 너무 작은 경우를 예시로 살펴보자."
      ],
      "metadata": {
        "id": "FOBMFD4GnTU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습률이 너무 큰 예 lr = 10.0\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x = init_x, lr = 10.0, step_num = 100)"
      ],
      "metadata": {
        "id": "fhS_uecclZee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2b3475-be2b-4971-9f7c-03f691592619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.58983747e+13, -1.29524862e+12])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습률이 너무 작은 예 lr = 1e-10\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x = init_x, lr = 1e-10, step_num = 100)"
      ],
      "metadata": {
        "id": "QIaqoqhq9-kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f578da-ac5f-435c-f54a-c3fd01800325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.99999994,  3.99999992])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 결과와 같이 학습률이 너무 크면 발산해버리고 너무 작으면 거의 학습되지 않은 채 끝난다.\n",
        "+ 학습률을 적절히 설정하는 것은 중요한 일임을 알 수 있다."
      ],
      "metadata": {
        "id": "QsG72mXi-YmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__  \n",
        "학습률 같은 매개변수를 __하이퍼파라미터__라고 한다.  \n",
        "이는 가중치와 편향같은 신경망의 매개변수와는 다르게 사람이 직접 설정해야하는 매개변수이다.  \n",
        "하이퍼파라미터들은 여러 후보 값 중에서 테스트를 통해 가장 잘 학습하는 값을 찾는 과정을 거쳐야한다."
      ],
      "metadata": {
        "id": "QiYN64R2-vcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.2 신경망에서의 기울기"
      ],
      "metadata": {
        "id": "xZf6uq7Pi1Io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망 학습에서는 가중치 매개변수에 대한 손실 함수의 기울기를 구해야한다.\n",
        "+ 예를들어 형상이 2×3, 가중치가 __W__, 손실 함수가 __L__인 신경망을 생각해보자.\n",
        "+ 경사는 $ \\frac{\\partial L}{\\partial W}$로 나타낼 수 있다. 수식은 다음과 같다."
      ],
      "metadata": {
        "id": "dUlw0oigi1VJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ W = \\begin{pmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23} \\end{pmatrix}$ <br/><br/>\n",
        "$ \\frac{\\partial L}{\\partial W} =  \\begin{pmatrix}\\frac{\\partial L}{\\partial w_{11}} &\\frac{\\partial L}{\\partial w_{12}} & \\frac{\\partial L}{\\partial w_{13}}\\\\ \\frac{\\partial L}{\\partial w_{21}} & \\frac{\\partial L}{\\partial w_{22}}& \\frac{\\partial L}{\\partial w_{23}} \\end{pmatrix}\n",
        "$"
      ],
      "metadata": {
        "id": "f9fBXQoni1gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ $ \\frac{\\partial L}{\\partial W}$ 의 각 원소는 각각의 원소에 관한 편미분이다.\n",
        "+ $ \\frac{\\partial L}{\\partial W}$ 의 형상과 __W__ 형상은 2×3으로 같음을 알 수 있다.\n",
        "+ 간단한 신경망을 예로 실제로 기울기를 구하는 코드를 구현해보자."
      ],
      "metadata": {
        "id": "pVqAdDxFCO2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/deep-learning-from-scratch-master/\")\n",
        "from common.functions import softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "class simpleNet:\n",
        "  def __init__(self):\n",
        "    self.W = np.random.randn(2,3) # 정규 분포로 초기화\n",
        "\n",
        "  def predict(self, x):\n",
        "    return np.dot(x, self.W)\n",
        "\n",
        "  def loss(self, x, t):\n",
        "    z = self.predict(x)\n",
        "    y = softmax(z)\n",
        "    loss = cross_entropy_error(y, t)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "hYygYrAEDTih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "simpleNet 클래스 : 2×3인 가중치 매개변수 하나를 인스턴스 변수로 가짐  \n",
        "predict(x) : 예측을 수행하는 메서드  \n",
        "loss(x) : 손실 함수의 값을 구하는 메서드  \n",
        "x : 입력 데이터 , t : 정답 레이블"
      ],
      "metadata": {
        "id": "ORjYDIV0F5mX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ simpleNet을 사용해 몇 가지 시험을 해보자."
      ],
      "metadata": {
        "id": "0E-macjiF_8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = simpleNet()\n",
        "print(net.W) # 가중치 매개변수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLNYCQrCEQPh",
        "outputId": "011dee57-3ea9-4a04-bb42-f0dc53d3bab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.07735564 -1.63849121 -0.63338669]\n",
            " [-0.51987063 -0.80954462 -0.90532912]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print(p)\n",
        "print(np.argmax(p)) # 최댓값의 인덱스"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD-DYnIgG8X1",
        "outputId": "7434bc4d-6ebf-4fd5-bfe2-4f2f1229531e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.17852982 -1.71168489 -1.19482822]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array([0, 0, 1]) # 정답 레이블\n",
        "print(net.loss(x, t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQgsy38yG-ap",
        "outputId": "374ccc35-8756-4fc7-edc9-0d13e6848120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7128925028163093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ numerical_gradient(f, x)를 써서 기울기를 구해보자."
      ],
      "metadata": {
        "id": "708dYvfTHC0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(W):\n",
        "  return net.loss(x, t)\n",
        "\n",
        "dW = numerical_gradient(f, net.W)\n",
        "print(dW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgirEeV5HGG9",
        "outputId": "03322331-e7df-4e9a-d5a5-0926bec7bfe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.42726058  0.06453317 -0.49179375]\n",
            " [ 0.64089087  0.09679976 -0.73769063]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ $ \\frac{\\partial L}{\\partial W}$의 $ \\frac{\\partial L}{\\partial w_{11}}$은 대략 0.1이다.  \n",
        "이는 $w_{11}$을 h 만큼 늘리면 손실 함수의 값은 0.1h만큼 증가한다는 의미이다."
      ],
      "metadata": {
        "id": "jNUerFkAIiFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ $ \\frac{\\partial L}{\\partial w_{23}}$은 약 -0.2이니, $ \\frac{\\partial L}{\\partial w_{23}}$을 h만큼 늘리면 손실 함수의 값은 0.2h 만큼 감소하는 것이다.\n",
        "+ 손실 함수를 줄인다는 관점에서 $w_{23}$ 은 양의 방향으로 갱신하고, $w_{11}$은 음의 방향으로 갱신해야 한다.\n",
        "+ 한 번에 갱신되는 양은 $w_{23}$이  $w_{11}$보다 크게 기여한다."
      ],
      "metadata": {
        "id": "A8oUY_PqIh6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 파이썬에서는 람다(lambda) 기법을 쓰면 간단한 함수를 편하게 구현 할 수 있다."
      ],
      "metadata": {
        "id": "YeqWV4ZQIhvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda w: net.loss(x, t)\n",
        "dW = numerical_gradient(f, net.W)"
      ],
      "metadata": {
        "id": "qMXd_NbONEn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 학습 알고리즘 구현하기"
      ],
      "metadata": {
        "id": "jXsDAP79IhW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망 학습은 다음과 같이 4단계로 수행한다."
      ],
      "metadata": {
        "id": "ksUvOXNBNbsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전제\n",
        "+ 신경망에는 적응 가능한 가중치와 편항이 있고,  \n",
        "가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습'이라 한다."
      ],
      "metadata": {
        "id": "_zWR37IvNbpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1단계 - 미니배치\n",
        "+ 훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며,  \n",
        "그 미니배치의 손실 함수 값을 줄이는 것이 목표이다."
      ],
      "metadata": {
        "id": "hGNs3okANbfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2단계 - 기울기 산출\n",
        "+ 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다.  \n",
        "기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다."
      ],
      "metadata": {
        "id": "-o0_ygF3NbU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3단계 - 매개변수 갱신\n",
        "+ 가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다."
      ],
      "metadata": {
        "id": "MetFWBtYN-Ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4단계 - 반복\n",
        "+ 1~3 단계를 반복한다."
      ],
      "metadata": {
        "id": "Xl_WXm3-ODUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이는 경사 하강법으로 매개변수를 갱신하는 방법이며,  \n",
        "데이터를 무작위로 선정하기 때문에 __확률적 경사 하강법__ 이라고 부른다.\n",
        "+ 대부분의 딥러닝 프레임워크는 __SGD__라는 함수로 이 기능을 구현하고 있다.\n",
        "+ 실제로 손글씨 숫자를 학습하는 신경망을 구현해보자."
      ],
      "metadata": {
        "id": "35zEPNX4OL8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.1 2층 신경망 클래스 구현하기"
      ],
      "metadata": {
        "id": "_XJw5vhyOXe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 2층 신경망을 하나에 클래스로 구현하는 것부터 시작한다."
      ],
      "metadata": {
        "id": "iBmhfMJpOrZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/deep-learning-from-scratch-master/\")\n",
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "\n",
        "        return y\n",
        "\n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return cross_entropy_error(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "        grads = {}\n",
        "\n",
        "        batch_num = x.shape[0]\n",
        "\n",
        "        # forward\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "\n",
        "        # backward\n",
        "        dy = (y - t) / batch_num\n",
        "        grads['W2'] = np.dot(z1.T, dy)\n",
        "        grads['b2'] = np.sum(dy, axis=0)\n",
        "\n",
        "        da1 = np.dot(dy, W2.T)\n",
        "        dz1 = sigmoid_grad(a1) * da1\n",
        "        grads['W1'] = np.dot(x.T, dz1)\n",
        "        grads['b1'] = np.sum(dz1, axis=0)\n",
        "\n",
        "        return grads"
      ],
      "metadata": {
        "id": "UlX-4T3eOzID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TwoLayerNet 클래스가 사용하는 변수"
      ],
      "metadata": {
        "id": "wis_dF1easZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|변수|설명|\n",
        "|------|---|\n",
        "|params|신경망의 매개변수를 보관하는 딕셔너리 변수|\n",
        "||params['W1']은 1번째 층의 가중치, params['b1']은 1번째 층의 편향|\n",
        "||params['W2']은 2번째 층의 가중치, params['b2']은 2번째 층의 편향|\n",
        "|grads|기울기 보관하는 딕셔너리 변수|\n",
        "||grads['W1']은 1번째 층의 가중치의 기울기, params['b1']은 1번째 층의 편향의 기울기|\n",
        "||grads['W2']은 2번째 층의 가중치의 기울기, params['b2']은 2번째 층의 편향의 기울기|"
      ],
      "metadata": {
        "id": "uvU6rnU5OrW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TwoLayerNet 클래스의 메서드"
      ],
      "metadata": {
        "id": "FmKvnsIgOrRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|메서드|설명|\n",
        "|------|---|\n",
        "|_ _ _init_ _ _(self.input_size, hidden_size, output_size)|초기화를 수행한다.|\n",
        "||인수는 순서대로 입력층의 뉴런 수, 은닉층의 뉴런 수, 출력층의 뉴런 수|\n",
        "|predict(self, x)|예측(추론)을 수행한다.|\n",
        "||인수 x는 이미지 데이터|\n",
        "|loss(self, x, t)|손실 함수의 값을 구현한다.|\n",
        "||인수 x는 이미지 데이터, t는 정답레이블(아래 칸의 인수들도 마찬가지)|\n",
        "|accuracy(self, x, t)|정확도를 구한다.|\n",
        "|numerical_gradient(self, x, t)|가중치 매개변수의 기울기를 구한다.|\n",
        "|gradient(self, x, t)|가중치 매개변수의 기울기를 구한다.|"
      ],
      "metadata": {
        "id": "RjxdsKZSOrLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ TwoLayerNet 클래스는 딕셔너리인 params와 grads를 인스턴스 변수로 갖는다.\n",
        "+ params 변수에는 가중치 매개변수가 저장된다.\n",
        "+ 1번째 층의 가중치는 params['W1'] 키에 넘파이 배열로 저장되고, 1번째 층의 편향은 params['b1'] 키로 저장된다."
      ],
      "metadata": {
        "id": "qsTcsPgQcn8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)\n",
        "print(net.params['W1'].shape)\n",
        "print(net.params['b1'].shape)\n",
        "print(net.params['W2'].shape)\n",
        "print(net.params['b2'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zeJhZ-EdUMw",
        "outputId": "138430d0-1a64-40de-da9f-0c935d2187df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이처럼 params 변수에는 신경망에 필요한 매개변수가 모두 저장된다.\n",
        "+ params 변수에 저장된 가중치 매개변수가 예측 처리(순방향 처리)에서 사용된다.\n",
        "+ 예측 처리는 다음과 같이 실행할 수 있다."
      ],
      "metadata": {
        "id": "rKwoOxtzdUco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(100, 784) # 더미 입력 데이터(100장 분량)\n",
        "y = net.predict(x)"
      ],
      "metadata": {
        "id": "f9s-jcrldvN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ grads 변수에는 params 변수에 대응하는 각 매개변수의 기울기가 저장된다."
      ],
      "metadata": {
        "id": "__KTdRRfdUWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(100, 784) # 더미 입력 데이터(100장 분량)\n",
        "t = np.random.rand(100, 10) # 더미 정답 데이터(100장 분량)\n",
        "\n",
        "grads = net.numerical_gradient(x, t) # 기울기 계산\n",
        "\n",
        "print(grads['W1'].shape)\n",
        "print(grads['b1'].shape)\n",
        "print(grads['W2'].shape)\n",
        "print(grads['b2'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltVJNZ-neDa_",
        "outputId": "1752f7c3-8d15-4dc7-bcd1-579d62d8613e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ TwoLayerNet의 메서드들을 살펴보자"
      ],
      "metadata": {
        "id": "p-GJ2GsVefXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_ _ init_ _(self, input_size, hidden_size, output_size) 메서드"
      ],
      "metadata": {
        "id": "7w56_viQgU_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ _ _ init_ _(self, input_size, hidden_size, output_size) 메서드는 클래스를 초기화 한다.\n",
        "+ 인수는 순서대로 입력층의 뉴런 수, 은닉층의 뉴런 수, 출력층의 뉴런 수이다.\n",
        "+ 예를 들어 손글씨 숫자 인식에서는 크기가 28×28인 입력 이미지가 784개이고 출력은 10개가 된다.  \n",
        "(input_size = 784, output_size = 10, 은닉층의 개수인 hidden_size는 적당한 값 설정)"
      ],
      "metadata": {
        "id": "TfT0KjB6efQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 초기화 메서드는 가중치 매개변수도 초기화 한다.\n",
        "+ 가중치 매개변수의 초깃값을 무엇으로 설정하냐가 신경망 학습의 성공을 좌우하기도 한다.\n",
        "+ 정규분포를 따르는 난수로, 편향은 0으로 초기화한다."
      ],
      "metadata": {
        "id": "opoGYkFkefMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict(self, x)와 accuracy(self, x, t)은 앞서 본 신경망의 추론 처리와 유사함."
      ],
      "metadata": {
        "id": "LhQtXykfefHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss(self, x, t) 메서드"
      ],
      "metadata": {
        "id": "vHwmRgtSefCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ loss(self, x, t)는 손실 함수의 값을 계산하는 메서드이다.\n",
        "+ predict()의 결과와 정답 레이블을 바탕으로 교차 엔트로피 오차를 구하도록 구현했다."
      ],
      "metadata": {
        "id": "xkJZ8Rt0gpuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "numerical_gradient(self, x, t) 메서드"
      ],
      "metadata": {
        "id": "hB1wH9__gzSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ numerical_gradient(self, x, t) 메서드는 각 매개변수의 기울기를 계산한다.\n",
        "+ 수치 미분 방식으로 각 매개변수의 손실 함수에 대한 기울기를 계산한다.\n"
      ],
      "metadata": {
        "id": "Bclc9KNzgzMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradient(self, x, t)"
      ],
      "metadata": {
        "id": "1wNpgNRTg-AW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ gradient(self, x, t)는 다음장에서 배울 오차역전파법을 사용하여 기울기를 효율적이고 빠르게 계산한다."
      ],
      "metadata": {
        "id": "WHvoUg7fhAPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.2 미니배치 학습 구현하기"
      ],
      "metadata": {
        "id": "OOmK7BZkhA1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 미니배치 학습을 활용하여 신경망 학습을 구현해보자."
      ],
      "metadata": {
        "id": "RKSzspfGhAxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from ch04.two_layer_net import TwoLayerNet\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "# 하이퍼파라미터\n",
        "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100   # 미니배치 크기\n",
        "learning_rate = 0.1\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # 미니배치 획득\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # 기울기 계산\n",
        "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "\n",
        "    # 매개변수 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    # 학습 경과 기록\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)"
      ],
      "metadata": {
        "id": "O68l6DPPntYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 매번 60,000개의 훈련 데이터에서 임의로 100개의 데이터(이미지 데이터와 정답 레이블 데이터)를 추려낸다.\n",
        "+ 100개의 미니배치를 대상으로 확률적 경사 하강법을 수행해 매개변수를 갱신한다.\n",
        "+ 경사법에 의한 갱신 횟수를 10,000번으로 설정하고,  \n",
        "갱신할 때마다 훈련 데이터에 대한 손실 함수를 계산하고 그 값을 배열에 추가한다.\n",
        "+ 손실 함수의 값이 변화하는 추이를 그래프로 나타내면 아래와 같다."
      ],
      "metadata": {
        "id": "whQfTs3MhAgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1_4rmg6E2hkknZwvjzS1XiPOvAy7F63jL' height = 300/><br>"
      ],
      "metadata": {
        "id": "P-OG99F4pdKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 학습 횟수가 늘어가면서 손실 함수의 값이 줄어든다. 이는 학습이 잘되고 있다는 뜻이다.\n",
        "+ 신경망의 가중치 매개변수가 서서히 데이터에 적응하고 있음을 의미한다."
      ],
      "metadata": {
        "id": "u1x6IU-7pgk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.3 시험 데이터로 평가하기"
      ],
      "metadata": {
        "id": "SRv9sKzIpgiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망 학스벵서는 훈련 데이터 외의 데이터를 올바르게 인식하는지 확인해야 한다.\n",
        "+ '오버피팅'을 일으키지 않는지 확인해야 하는데, 이는 훈련 데이터에 포함된 이미지만 구분하고, 그렇지 않은 이미지는 식별할 수 없다는 뜻이다.\n",
        "+ 맨 오른쪽 그래프처럼 훈련 데이터에 과하게 치중되어 다른 데이터는 식별할 수 없는 것을 의미한다."
      ],
      "metadata": {
        "id": "0Spg8dqRpgf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1gc5djEON-pk-Y7jAB6msZswwmKNZAWX9' /><br>"
      ],
      "metadata": {
        "id": "qonAPsgdpgdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 신경망 학습의 범용 능력을 평가하기 위해 훈련 데이터에 포함되지 않은 데이터를 사용해 평가한다.\n",
        "+ 여기서는 1에폭별로 훈련 데이터와 시험 데이터에 대한 정확도를 기록한다."
      ],
      "metadata": {
        "id": "fYgsurf3pgQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__  \n",
        "__에폭__은 하나의 단위이다. 1에폭은 훈련 데이터를 모두 소진했을 때의 횟수에 해당한다.  \n",
        "예를들어 10,000개를 100개의 미니배치로 학습할 경우,  \n",
        "확률적 경사 하강법을 100회 반복하면 모든 훈련 데이터를 소진한 게 된다. 이 경우 100회가 1에폭이 된다."
      ],
      "metadata": {
        "id": "BCjAgPrDrFyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 에폭을 추가하여 구현해보자."
      ],
      "metadata": {
        "id": "1bXzWcOhreD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from ch04.two_layer_net import TwoLayerNet\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 1에폭당 반복 수\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "# 하이퍼파라미터\n",
        "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100   # 미니배치 크기\n",
        "learning_rate = 0.1\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # 미니배치 획득\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # 기울기 계산\n",
        "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "\n",
        "    # 매개변수 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    # 학습 경과 기록\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    # 1에폭당 정확도 계산\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ReDftirf7G",
        "outputId": "ffd43f73-7dc4-4888-f13a-97d9f0792988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc, test acc | 0.0993, 0.1032\n",
            "train acc, test acc | 0.7833666666666667, 0.7886\n",
            "train acc, test acc | 0.8766, 0.8812\n",
            "train acc, test acc | 0.89805, 0.9022\n",
            "train acc, test acc | 0.9086, 0.9118\n",
            "train acc, test acc | 0.9138166666666667, 0.917\n",
            "train acc, test acc | 0.9194666666666667, 0.9225\n",
            "train acc, test acc | 0.9244833333333333, 0.9268\n",
            "train acc, test acc | 0.9282666666666667, 0.9306\n",
            "train acc, test acc | 0.93095, 0.9304\n",
            "train acc, test acc | 0.9346833333333333, 0.9351\n",
            "train acc, test acc | 0.9372, 0.9387\n",
            "train acc, test acc | 0.9399833333333333, 0.9398\n",
            "train acc, test acc | 0.9413, 0.9406\n",
            "train acc, test acc | 0.9437, 0.943\n",
            "train acc, test acc | 0.9462, 0.9458\n",
            "train acc, test acc | 0.9482666666666667, 0.9472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 예에서는 1에폭마다 모든 훈련 데이터와 시험 데이터에 대한 정확도를 계산하고 결과를 기록한다.\n",
        "+ 정확도를 1에폭마다 계산하는 이유는 for 문 안에서 매번 계산하기에 오래 걸리고,  \n",
        "더 큰 관점에서 그 추이를 알 수 있으면 충분하기 때문이다.\n",
        "+ 위 결과를 그래프로 그려보자."
      ],
      "metadata": {
        "id": "31CvXYCxrv_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 그리기\n",
        "# 훈련 데이터와 시험 데이터에 대한 정확도 추이\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, label='train acc')\n",
        "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "1uu8a_9Kru0u",
        "outputId": "95ec507e-b430-4ddf-90db-3055fc302b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 훈련 데이터에 대한 정확도는 실선으로, 시험 데이터에 대한 정확도는 점선으로 그렸다.\n",
        "+ 에폭이 진행될수록(학습이 진행될수록) 훈련 데이터와 시험 데이터를 사용하고 평가한 정확도가 모두 좋아졌다.\n",
        "+ 두 정확도에는 차이가 없음을 알 수 있다. 즉 오버피팅이 일어나지 않았음을 의미한다."
      ],
      "metadata": {
        "id": "goBkyr4ssPQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6 정리"
      ],
      "metadata": {
        "id": "EKHe4Ji5iI9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 기계학습에서 사용하는 데이터셋은훈련 데이터와 시험 데이터로 나눠 사용한다.\n",
        "+ 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가한다.\n",
        "+ 신경망 학습은 손실 함수를 지표로,  \n",
        "손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신한다.\n",
        "+ 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고,  \n",
        "기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복한다.\n",
        "+ 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 수치 미분이라고 한다.\n",
        "+ 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있다.\n",
        "+ 수치 미분을 이용한 계산은 간단한 대신 시간이 걸리지만,  \n",
        "다소 복잡한 오차역전파법으로 기울기를 고속으로 구할 수 있다."
      ],
      "metadata": {
        "id": "0dDgo5p1iKjk"
      }
    }
  ]
}